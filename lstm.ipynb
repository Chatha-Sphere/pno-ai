{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import PreprocessingPipeline\n",
    "from helpers import one_hot, prepare_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed MIDI-Unprocessed_Chamber2_MID--AUDIO_09_R3_2018_wav--3.midi\n",
      "Successfully parsed MIDI-Unprocessed_Chamber1_MID--AUDIO_07_R3_2018_wav--2.midi\n",
      "Successfully parsed MIDI-Unprocessed_Chamber2_MID--AUDIO_09_R3_2018_wav--1.midi\n",
      "\n",
      "3 midis read, or 3574.0 minutes of music\n",
      "3 note sequences\n",
      "\n",
      "Processing training data...\n",
      "2 note sequences\n",
      "10 stretched note sequences\n",
      "61 quantized, split samples\n",
      "427 transposed samples\n",
      "0 / 427 sequences encoded\n",
      "100 / 427 sequences encoded\n",
      "200 / 427 sequences encoded\n",
      "300 / 427 sequences encoded\n",
      "400 / 427 sequences encoded\n",
      "7 sequences discarded due to brevity\n",
      "294 sequences truncated due to excessive length.\n",
      "Encoded training sequences!\n",
      "\n",
      "Processing validation data...\n",
      "1 note sequences\n",
      "21 quantized, split samples\n",
      "0 / 21 sequences encoded\n",
      "7 sequences discarded due to brevity\n",
      "314 sequences truncated due to excessive length.\n",
      "Encoded validation sequences!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = PreprocessingPipeline(input_dir=\"data/test\", training_val_split=0.7, \n",
    "                                 sequence_length=(33,512))\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have to offset sequences by one so that target sequences are always\n",
    "#one time step ahead: e.g. given sequence \"Hello World\"\n",
    "# we have target \"ello World\" and input \"Hello Worl\"\n",
    "input_sequences = [s[:-1] for s in pipeline.encoded_sequences['training']]\n",
    "target_sequences = [s[1:] for s in pipeline.encoded_sequences['training']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_batches = prepare_batches(input_sequences, 64, 413, 512)\n",
    "target_batches = prepare_batches(target_sequences, 64, 413, 512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
